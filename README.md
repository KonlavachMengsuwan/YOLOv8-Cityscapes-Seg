# YOLOv8-Cityscapes-Seg
```
import os
import json
import cv2
import numpy as np
import torch
import matplotlib.pyplot as plt
from tqdm import tqdm
from PIL import Image
from ultralytics import YOLO

# ============================== #
#  âœ… 1. SETUP ENVIRONMENT       #
# ============================== #

# Check CUDA availability
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"âœ… Using device: {device}")

# Create directories if not exist
CITYSCAPES_ROOT = "cityscapes"
IMAGE_DIR = os.path.join(CITYSCAPES_ROOT, "leftImg8bit")
ANNOTATION_DIR = os.path.join(CITYSCAPES_ROOT, "gtFine")
YOLO_LABELS_DIR = os.path.join(CITYSCAPES_ROOT, "labels_yolo")

os.makedirs(YOLO_LABELS_DIR, exist_ok=True)

# Define Cityscapes classes
CLASS_NAMES = ["road", "sidewalk", "building", "wall", "fence", "pole",
               "traffic light", "traffic sign", "vegetation", "terrain",
               "sky", "person", "rider", "car", "truck", "bus", "train",
               "motorcycle", "bicycle"]
CLASS_DICT = {name: i for i, name in enumerate(CLASS_NAMES)}

# ============================== #
#  âœ… 2. CONVERT CITYSCAPES TO YOLO FORMAT  #
# ============================== #

def convert_cityscapes_to_yolo():
    """ Convert Cityscapes annotation to YOLO segmentation format. """
    for split in ["train", "val"]:
        img_split_dir = os.path.join(IMAGE_DIR, split)
        ann_split_dir = os.path.join(ANNOTATION_DIR, split)
        yolo_split_dir = os.path.join(YOLO_LABELS_DIR, split)
        os.makedirs(yolo_split_dir, exist_ok=True)

        for city in tqdm(os.listdir(img_split_dir), desc=f"Processing {split} set"):
            img_files = os.listdir(os.path.join(img_split_dir, city))
            for img_file in img_files:
                img_path = os.path.join(img_split_dir, city, img_file)
                ann_file = img_file.replace("leftImg8bit.png", "gtFine_polygons.json")
                ann_path = os.path.join(ann_split_dir, city, ann_file)
                label_path = os.path.join(yolo_split_dir, img_file.replace(".png", ".txt"))

                if not os.path.exists(ann_path):
                    continue  # Skip if annotation is missing

                with open(ann_path, "r") as f:
                    ann_data = json.load(f)

                img = cv2.imread(img_path)
                img_h, img_w = img.shape[:2]

                with open(label_path, "w") as f:
                    for obj in ann_data["objects"]:
                        label = obj["label"]
                        if label in CLASS_DICT:
                            class_id = CLASS_DICT[label]
                            polygon = np.array(obj["polygon"], dtype=np.float32)
                            polygon[:, 0] /= img_w  # Normalize x-coordinates
                            polygon[:, 1] /= img_h  # Normalize y-coordinates
                            poly_str = " ".join(map(str, polygon.flatten().tolist()))
                            f.write(f"{class_id} {poly_str}\n")

# Convert dataset if not already converted
if not os.path.exists(YOLO_LABELS_DIR):
    convert_cityscapes_to_yolo()
    print("âœ… Cityscapes dataset converted to YOLO format.")

# ============================== #
#  âœ… 3. CREATE data.yaml FILE   #
# ============================== #

data_yaml_path = os.path.join(CITYSCAPES_ROOT, "data.yaml")

if not os.path.exists(data_yaml_path):
    with open(data_yaml_path, "w") as f:
        f.write(f"""path: {CITYSCAPES_ROOT}
train: leftImg8bit/train
val: leftImg8bit/val
nc: {len(CLASS_NAMES)}
names: {CLASS_NAMES}
""")
    print("âœ… data.yaml created successfully.")

# ============================== #
#  âœ… 4. TRAIN YOLOv8 ON CITYSCAPES   #
# ============================== #

# Load YOLOv8 segmentation model
model = YOLO("yolov8n-seg.pt")  # Use 's', 'm', 'l' for larger models

# Train the model
model.train(data=data_yaml_path, epochs=20, batch=8, imgsz=640, device=device)

# Save the best trained model path
trained_model_path = "runs/segment/train/weights/best.pt"
print(f"âœ… Training completed. Best model saved at: {trained_model_path}")

# ============================== #
#  âœ… 5. RUN INFERENCE ON CUSTOM IMAGES   #
# ============================== #

def run_inference(image_path):
    """ Run YOLOv8 segmentation inference on a given image. """
    model = YOLO(trained_model_path)
    results = model(image_path)

    for result in results:
        annotated_img = result.plot()
        plt.imshow(annotated_img)
        plt.axis('off')
        plt.show()

# Example: Run inference on your custom image
custom_image_path = "path/to/your/image.jpg"  # Change this to your image
if os.path.exists(custom_image_path):
    print(f"âœ… Running inference on: {custom_image_path}")
    run_inference(custom_image_path)
else:
    print("âš ï¸ Custom image not found. Please update 'custom_image_path'.")

# ============================== #
#  âœ… 6. RUN INFERENCE ON VIDEO (OPTIONAL)  #
# ============================== #

def run_video_inference(video_path):
    """ Run YOLOv8 segmentation inference on a video. """
    model.predict(source=video_path, save=True, device=device)

# Example: Run inference on a video file
video_path = "path/to/your/video.mp4"  # Change this to your video file
if os.path.exists(video_path):
    print(f"âœ… Running inference on: {video_path}")
    run_video_inference(video_path)
else:
    print("âš ï¸ Video file not found. Please update 'video_path'.")

```

ğŸ“Œ How This Script Works
âœ” 1. Checks CUDA & Sets Up Environment (Fast execution)
âœ” 2. Converts Cityscapes dataset to YOLO segmentation format
âœ” 3. Creates data.yaml file automatically
âœ” 4. Trains YOLOv8 segmentation model with optimized settings
âœ” 5. Runs inference on custom images (Shows results)
âœ” 6. Runs inference on videos (Saves results)

ğŸš€ How to Use This Script
1ï¸âƒ£ Download & Extract Cityscapes Dataset
- Download leftImg8bit_trainvaltest.zip
- Download gtFine_trainvaltest.zip
- Extract both into cityscapes/
  
2ï¸âƒ£ Run the script on your PC with CUDA

```
python train_yolo_cityscapes.py
```

3ï¸âƒ£ Check results in runs/segment/train/
4ï¸âƒ£ Modify custom_image_path to test your images
5ï¸âƒ£ Modify video_path to test on a video

ğŸ”¥ Optimizations in This Script
âœ… Efficient Dataset Conversion (Runs only once)
âœ… Auto-detects CUDA (Runs smoothly on GPU)
âœ… Uses Fast Training Settings (batch=8, imgsz=640, epochs=20)
âœ… Runs Inference on Images & Videos

ğŸš€ Recommended Directory Structure
```
YOLOv8_Cityscapes/
â”œâ”€â”€ cityscapes/                  # Root folder for Cityscapes dataset
â”‚   â”œâ”€â”€ leftImg8bit/             # Cityscapes images
â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ gtFine/                  # Cityscapes fine annotations
â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ labels_yolo/             # Converted YOLO format labels
â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ data.yaml                 # YOLO dataset config file
â”œâ”€â”€ runs/                         # YOLO training results (auto-generated)
â”‚   â”œâ”€â”€ segment/
â”‚   â”‚   â”œâ”€â”€ train/                # Model training results
â”‚   â”‚   â”‚   â”œâ”€â”€ weights/          # Trained models (best.pt, last.pt)
â”‚   â”‚   â”‚   â”œâ”€â”€ results.png       # Training graph
â”‚   â”‚   â”‚   â”œâ”€â”€ train_batch0.jpg  # Sample batch visualizations
â”‚   â”‚   â”‚   â”œâ”€â”€ val_batch0_labels.jpg  # Validation results
â”‚   â”‚   â”œâ”€â”€ predict/              # Inference output folder
â”‚   â”‚   â”‚   â”œâ”€â”€ image1.jpg        # Processed images
â”‚   â”‚   â”‚   â”œâ”€â”€ image2.jpg
â”‚   â”‚   â”‚   â”œâ”€â”€ video_output.mp4  # Processed video
â”œâ”€â”€ scripts/                      # Python scripts for dataset and model
â”‚   â”œâ”€â”€ convert_cityscapes_to_yolo.py  # Conversion script
â”‚   â”œâ”€â”€ train_yolo_cityscapes.py       # Training script
â”‚   â”œâ”€â”€ run_inference.py               # Inference script
â”œâ”€â”€ models/                        # Store different model versions
â”‚   â”œâ”€â”€ yolov8n-seg.pt              # Pretrained YOLOv8 segmentation model
â”‚   â”œâ”€â”€ best_cityscapes.pt          # Best trained model from Cityscapes
â”‚   â”œâ”€â”€ last_cityscapes.pt          # Last trained model checkpoint
â”œâ”€â”€ custom_data/                   # Your own images/videos for inference
â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”œâ”€â”€ test_image.jpg          # Custom test image
â”‚   â”œâ”€â”€ videos/
â”‚   â”‚   â”œâ”€â”€ test_video.mp4          # Custom test video
â”œâ”€â”€ README.md                      # Project documentation
â”œâ”€â”€ requirements.txt                # Dependencies list
```

ğŸ“Œ Explanation of Key Folders

ğŸ“ cityscapes/
- Contains the Cityscapes dataset (original images + annotations)
- leftImg8bit/: RGB images for training/validation
- gtFine/: Segmentation masks in original Cityscapes format
- labels_yolo/: Converted YOLO format labels

ğŸ“ runs/segment/ (Auto-generated by YOLO)
- train/weights/: Stores best.pt (best model) and last.pt (latest model)
- train/results.png: Training loss curves
- predict/: Stores segmentation results from inference

ğŸ“ scripts/
- Houses Python scripts for dataset conversion, training, and inference
- convert_cityscapes_to_yolo.py: Converts Cityscapes annotations to YOLO format
- train_yolo_cityscapes.py: Runs YOLOv8 training on Cityscapes
- run_inference.py: Runs segmentation on your own images/videos


ğŸ“ models/
- Stores trained YOLOv8 models for future testing or sharing
- best_cityscapes.pt: Best trained model (use this for inference)
- last_cityscapes.pt: Last model checkpoint

ğŸ“ custom_data/
- Contains your own images/videos to test after training
- images/: Store custom images for inference
- videos/: Store custom videos for segmentation

ğŸ“„ README.md
- Explain your project (e.g., how to train, test, and use the model)

ğŸ“„ requirements.txt
- List of Python dependencies (so others can run your project easily)

```
ultralytics
torch
torchvision
opencv-python
matplotlib
numpy
tqdm
pillow
```

Generate this file automatically by running:
```
pip freeze > requirements.txt
```

ğŸ”¥ How to Use This Structure?
ğŸš€ 1ï¸âƒ£ Convert Cityscapes to YOLO Format
```
python scripts/convert_cityscapes_to_yolo.py
```

ğŸš€ 2ï¸âƒ£ Train YOLOv8 Segmentation on Cityscapes
```
python scripts/train_yolo_cityscapes.py
```

ğŸš€ 3ï¸âƒ£ Run Inference on Custom Images
```
python scripts/run_inference.py --image custom_data/images/test_image.jpg
```

ğŸš€ 4ï¸âƒ£ Run Inference on Custom Video
```
python scripts/run_inference.py --video custom_data/videos/test_video.mp4
```
